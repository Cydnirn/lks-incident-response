import type { IncidentTicket } from '../types/ticket';

export const mockTickets: IncidentTicket[] = [
  {
    id: "INC-001",
    title: "Kubernetes Node CPU Full - Production Cluster",
    description: "Multiple nodes in the production Kubernetes cluster are experiencing 100% CPU utilization, causing pod scheduling issues and service degradation.",
    report: "Investigation revealed that several microservices were consuming excessive CPU resources due to inefficient database queries. The issue was identified through monitoring alerts and pod metrics analysis.",
    suggestions: [
      "Implement horizontal pod autoscaling (HPA) with CPU-based metrics",
      "Optimize database queries in affected microservices",
      "Add resource limits and requests to all deployments",
      "Consider implementing circuit breakers for database connections"
    ],
    severity: "critical",
    category: "kubernetes",
    insident_type: "CPU_HIGH",
    environment: "production",
    actionStatus: "auto",
    status: "solved",
    reporter: "Monitoring System",
    createdAt: "2025-01-15T10:30:00Z",
    resolutionTime: "2 hours 15 minutes",
    emailSent: true,
    emailSentAt: "2024-01-15T10:35:00Z",
    actionTaken: "Auto-scaled pods and implemented CPU limits. Database queries were optimized and HPA was configured.",
    affectedServices: ["user-service", "payment-service", "notification-service"],
    tags: ["kubernetes", "cpu", "autoscaling", "production"]
  },
  {
    id: "INC-002",
    title: "Pod CrashLoopBackOff - Database Service",
    description: "Database service pods are continuously crashing and restarting, causing application downtime and data access issues.",
    report: "Root cause analysis identified a memory leak in the database connection pool. The service was consuming more memory than allocated, leading to OOM kills and subsequent crashes.",
    suggestions: [
      "Increase memory limits for database service pods",
      "Implement connection pooling with proper cleanup",
      "Add health checks and readiness probes",
      "Monitor memory usage patterns"
    ],
    severity: "high",
    category: "kubernetes",
    insident_type: "POD_CRASH",
    environment: "production",
    actionStatus: "manual",
    status: "in-progress",
    reporter: "Kubernetes Scheduler",
    createdAt: "2025-01-16T14:20:00Z",
    resolutionTime: "1 hour 45 minutes",
    emailSent: true,
    emailSentAt: "2024-01-16T14:25:00Z",
    actionTaken: "Manually restarted pods with increased memory limits and implemented connection pool monitoring.",
    affectedServices: ["database-service", "api-gateway"],
    tags: ["database", "crashloopbackoff", "memory", "connection-pool"]
  },
  {
    id: "INC-003",
    title: "HPA Scaling Failure - Load Balancer",
    description: "Horizontal Pod Autoscaler is unable to scale pods due to insufficient node resources, causing performance degradation during peak traffic.",
    report: "Analysis showed that the cluster was running at 95% capacity with no available resources for new pods. The HPA was trying to scale but couldn't schedule new pods.",
    suggestions: [
      "Add more worker nodes to the cluster",
      "Implement cluster autoscaler",
      "Optimize resource requests and limits",
      "Consider using spot instances for cost optimization"
    ],
    severity: "high",
    category: "kubernetes",
    insident_type: "UNHEALTHY_POD",
    environment: "production",
    actionStatus: "pending",
    status: "open",
    reporter: "HPA Controller",
    createdAt: "2025-01-17T09:15:00Z",
    emailSent: false,
    affectedServices: ["web-service", "api-service", "cache-service"],
    tags: ["hpa", "scaling", "resources", "autoscaling"]
  },
  {
    id: "INC-004",
    title: "Network Policy Blocking Service Communication",
    description: "Newly implemented network policies are blocking legitimate service-to-service communication, causing application failures.",
    report: "The network policies were too restrictive and didn't account for all required service communication patterns. This was discovered during deployment of a new microservice.",
    suggestions: [
      "Review and update network policy rules",
      "Implement network policy testing in CI/CD",
      "Use service mesh for better traffic management",
      "Document all service communication requirements"
    ],
    severity: "medium",
    category: "infrastructure",
    insident_type: "APP_ERROR",
    environment: "staging",
    actionStatus: "manual",
    status: "solved",
    reporter: "DevOps Engineer",
    createdAt: "2025-01-18T16:45:00Z",
    resolutionTime: "45 minutes",
    emailSent: true,
    emailSentAt: "2024-01-18T16:50:00Z",
    actionTaken: "Updated network policies to allow required service communication and added monitoring for policy violations.",
    affectedServices: ["auth-service", "user-service", "notification-service"],
    tags: ["network-policy", "security", "service-mesh", "communication"]
  },
  {
    id: "INC-005",
    title: "Persistent Volume Claim Failure",
    description: "PVC creation is failing due to insufficient storage capacity in the cluster, affecting stateful applications.",
    report: "The storage class was configured with a storage pool that had reached its capacity limit. New PVCs couldn't be provisioned, affecting database and file storage services.",
    suggestions: [
      "Expand storage capacity or add new storage pools",
      "Implement storage monitoring and alerts",
      "Consider using dynamic provisioning",
      "Review and clean up unused PVCs"
    ],
    severity: "medium",
    category: "infrastructure",
    insident_type: "OTHER",
    environment: "development",
    actionStatus: "auto",
    status: "closed",
    reporter: "Storage Controller",
    createdAt: "2025-01-19T11:30:00Z",
    emailSent: true,
    emailSentAt: "2024-01-19T11:35:00Z",
    actionTaken: "Automatically cleaned up unused PVCs and expanded storage capacity. Issue closed after infrastructure review.",
    affectedServices: ["file-service", "backup-service"],
    tags: ["pvc", "storage", "capacity", "statefulset"]
  },
  {
    id: "INC-006",
    title: "CI/CD Pipeline Failure - Security Scan",
    description: "Security scanning step in the CI/CD pipeline is failing due to newly discovered vulnerabilities, blocking deployments.",
    report: "The security scan detected critical vulnerabilities in third-party dependencies. The pipeline was configured to fail on high-severity findings, preventing deployment to production.",
    suggestions: [
      "Update vulnerable dependencies to patched versions",
      "Implement vulnerability scanning in development",
      "Configure security policy exceptions where appropriate",
      "Set up automated dependency updates"
    ],
    severity: "medium",
    category: "ci-cd",
    insident_type: "APP_ERROR",
    environment: "production",
    actionStatus: "manual",
    status: "in-progress",
    reporter: "CI/CD System",
    createdAt: "2025-01-20T13:20:00Z",
    emailSent: true,
    emailSentAt: "2024-01-20T13:25:00Z",
    actionTaken: "Manually updating dependencies and reviewing security findings. Pipeline temporarily bypassed for critical deployment.",
    affectedServices: ["deployment-pipeline", "security-scanner"],
    tags: ["ci-cd", "security", "vulnerabilities", "dependencies"]
  },
  {
    id: "INC-007",
    title: "Monitoring System Outage",
    description: "Prometheus monitoring system is down, causing loss of visibility into application and infrastructure metrics.",
    report: "The monitoring system experienced a disk space issue followed by a configuration corruption. This resulted in loss of historical data and inability to collect new metrics.",
    suggestions: [
      "Implement monitoring system redundancy",
      "Set up disk space monitoring and alerts",
      "Regular backup of monitoring configuration",
      "Consider using managed monitoring services"
    ],
    severity: "high",
    category: "infrastructure",
    insident_type: "OTHER",
    environment: "production",
    actionStatus: "auto",
    status: "solved",
    reporter: "Alert Manager",
    createdAt: "2025-01-21T08:45:00Z",
    resolutionTime: "1 hour 30 minutes",
    emailSent: true,
    emailSentAt: "2024-01-21T08:50:00Z",
    actionTaken: "Auto-restored monitoring system from backup and expanded storage capacity. Implemented additional monitoring redundancy.",
    affectedServices: ["prometheus", "grafana", "alertmanager"],
    tags: ["monitoring", "prometheus", "metrics", "backup"]
  },
  {
    id: "INC-008",
    title: "Infrastructure Security Breach Attempt",
    description: "Multiple failed login attempts detected on infrastructure components, indicating potential security breach attempt.",
    report: "Security monitoring detected unusual login patterns from multiple IP addresses. Investigation revealed a coordinated attack attempt on SSH and web interfaces.",
    suggestions: [
      "Implement IP whitelisting for admin access",
      "Enable two-factor authentication",
      "Review and update security groups",
      "Set up intrusion detection systems"
    ],
    severity: "critical",
    category: "infrastructure",
    insident_type: "OTHER",
    environment: "production",
    actionStatus: "manual",
    status: "open",
    reporter: "Security System",
    createdAt: "2025-01-22T19:30:00Z",
    emailSent: true,
    emailSentAt: "2024-01-22T19:35:00Z",
    actionTaken: "Manually blocked suspicious IP addresses and initiated security review. Enhanced monitoring and alerting implemented.",
    affectedServices: ["bastion-host", "load-balancer", "api-gateway"],
    tags: ["security", "breach", "authentication", "firewall"]
  },
  {
    id: "INC-009",
    title: "Database Connection Pool Exhaustion",
    description: "Database connection pool has reached maximum capacity, causing application timeouts and service degradation.",
    report: "High traffic load caused the connection pool to exhaust all available connections. Applications were unable to establish new database connections, leading to cascading failures.",
    suggestions: [
      "Increase connection pool size",
      "Implement connection pooling monitoring",
      "Add connection timeout configurations",
      "Consider database read replicas"
    ],
    severity: "high",
    category: "infrastructure",
    insident_type: "APP_ERROR",
    environment: "production",
    actionStatus: "auto",
    status: "solved",
    reporter: "Database Monitor",
    createdAt: "2025-01-23T12:15:00Z",
    resolutionTime: "30 minutes",
    emailSent: true,
    emailSentAt: "2025-01-23T12:20:00Z",
    actionTaken: "Auto-scaled connection pool and implemented connection monitoring. Added read replicas for load distribution.",
    affectedServices: ["user-service", "payment-service", "order-service"],
    tags: ["database", "connection-pool", "performance", "scaling"]
  },
  {
    id: "INC-010",
    title: "Load Balancer Health Check Failures",
    description: "Multiple backend services are failing health checks, causing load balancer to route traffic to unhealthy instances.",
    report: "Health check failures were caused by high memory usage and slow response times. The load balancer was correctly identifying unhealthy instances but had limited healthy backends.",
    suggestions: [
      "Optimize application memory usage",
      "Implement circuit breakers",
      "Add health check monitoring",
      "Scale backend services"
    ],
    severity: "medium",
    category: "infrastructure",
    insident_type: "UNHEALTHY_POD",
    environment: "production",
    actionStatus: "manual",
    status: "in-progress",
    reporter: "Load Balancer",
    createdAt: "2025-01-24T15:30:00Z",
    emailSent: true,
    emailSentAt: "2025-01-24T15:35:00Z",
    actionTaken: "Manually scaling backend services and implementing memory optimization. Health check thresholds adjusted.",
    affectedServices: ["api-gateway", "user-service", "notification-service"],
    tags: ["load-balancer", "health-checks", "scaling", "performance"]
  },
  // 2024 Data for comparison
  {
    id: "INC-2024-001",
    title: "Kubernetes Cluster Outage - 2024",
    description: "Production Kubernetes cluster experienced complete outage due to network connectivity issues.",
    report: "Network switch failure caused cluster-wide connectivity issues. All pods became unreachable and services were down for 2 hours.",
    suggestions: [
      "Implement redundant network infrastructure",
      "Add network monitoring and alerts",
      "Create disaster recovery procedures",
      "Test failover scenarios regularly"
    ],
    severity: "critical",
    category: "kubernetes",
    insident_type: "OTHER",
    environment: "production",
    actionStatus: "manual",
    status: "solved",
    reporter: "Network Monitor",
    createdAt: "2024-03-15T08:30:00Z",
    resolutionTime: "2 hours 30 minutes",
    emailSent: true,
    emailSentAt: "2024-03-15T08:35:00Z",
    actionTaken: "Manually switched to backup network infrastructure and restored cluster connectivity.",
    affectedServices: ["all-services"],
    tags: ["kubernetes", "network", "outage", "production"]
  },
  {
    id: "INC-2024-002",
    title: "Database Performance Degradation - 2024",
    description: "Database performance significantly degraded due to slow queries and connection pool exhaustion.",
    report: "Analysis revealed inefficient queries and lack of proper indexing. Connection pool was exhausted during peak hours.",
    suggestions: [
      "Optimize database queries",
      "Add proper indexes",
      "Implement query caching",
      "Scale database resources"
    ],
    severity: "high",
    category: "infrastructure",
    insident_type: "APP_ERROR",
    environment: "production",
    actionStatus: "auto",
    status: "solved",
    reporter: "Database Monitor",
    createdAt: "2024-06-20T14:15:00Z",
    resolutionTime: "1 hour 45 minutes",
    emailSent: true,
    emailSentAt: "2024-06-20T14:20:00Z",
    actionTaken: "Auto-optimized queries and added database indexes. Implemented connection pooling improvements.",
    affectedServices: ["user-service", "payment-service"],
    tags: ["database", "performance", "queries", "indexing"]
  },
  {
    id: "INC-2024-003",
    title: "Security Vulnerability Detected - 2024",
    description: "Critical security vulnerability detected in third-party dependency library.",
    report: "Security scan identified CVE-2024-1234 in a widely used dependency. Immediate action required to prevent potential exploitation.",
    suggestions: [
      "Update vulnerable dependency immediately",
      "Implement security scanning in CI/CD",
      "Review all dependencies regularly",
      "Create security incident response plan"
    ],
    severity: "critical",
    category: "infrastructure",
    insident_type: "OTHER",
    environment: "production",
    actionStatus: "manual",
    status: "solved",
    reporter: "Security Scanner",
    createdAt: "2024-09-10T10:00:00Z",
    resolutionTime: "45 minutes",
    emailSent: true,
    emailSentAt: "2024-09-10T10:05:00Z",
    actionTaken: "Manually updated dependency and deployed security patch. Implemented automated security scanning.",
    affectedServices: ["api-gateway", "authentication-service"],
    tags: ["security", "vulnerability", "dependency", "patch"]
  },
  {
    id: "INC-2024-004",
    title: "Load Balancer Configuration Error - 2024",
    description: "Load balancer configuration error caused service routing issues and increased latency.",
    report: "Recent configuration change introduced routing rules that caused traffic to be misrouted to incorrect backend services.",
    suggestions: [
      "Implement configuration validation",
      "Add load balancer monitoring",
      "Create rollback procedures",
      "Test configuration changes in staging"
    ],
    severity: "medium",
    category: "infrastructure",
    insident_type: "APP_ERROR",
    environment: "production",
    actionStatus: "manual",
    status: "solved",
    reporter: "Load Balancer Monitor",
    createdAt: "2024-11-05T16:45:00Z",
    resolutionTime: "30 minutes",
    emailSent: true,
    emailSentAt: "2024-11-05T16:50:00Z",
    actionTaken: "Manually reverted configuration change and restored proper routing. Implemented configuration validation.",
    affectedServices: ["web-service", "api-service"],
    tags: ["load-balancer", "configuration", "routing", "latency"]
  },
  {
    id: "INC-2024-005",
    title: "Monitoring System Failure - 2024",
    description: "Monitoring system experienced complete failure, causing loss of visibility into application health.",
    report: "Prometheus server crashed due to disk space exhaustion and corrupted time-series database.",
    suggestions: [
      "Implement monitoring redundancy",
      "Add disk space monitoring",
      "Regular backup of monitoring data",
      "Use managed monitoring services"
    ],
    severity: "high",
    category: "infrastructure",
    insident_type: "OTHER",
    environment: "production",
    actionStatus: "auto",
    status: "solved",
    reporter: "Alert Manager",
    createdAt: "2024-12-15T09:30:00Z",
    resolutionTime: "2 hours 15 minutes",
    emailSent: true,
    emailSentAt: "2024-12-15T09:35:00Z",
    actionTaken: "Auto-restored monitoring system from backup and expanded storage. Implemented monitoring redundancy.",
    affectedServices: ["prometheus", "grafana", "alertmanager"],
    tags: ["monitoring", "prometheus", "backup", "storage"]
  }
]; 